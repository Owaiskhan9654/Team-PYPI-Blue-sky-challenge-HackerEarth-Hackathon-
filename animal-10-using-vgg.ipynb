{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"b4739e22-3db0-4486-a496-68a67e48a46b","_cell_guid":"f11e5b8f-90a4-468b-95be-2e074c68a1ce","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:56:10.681982Z","iopub.execute_input":"2023-10-01T13:56:10.682554Z","iopub.status.idle":"2023-10-01T13:56:43.843479Z","shell.execute_reply.started":"2023-10-01T13:56:10.682522Z","shell.execute_reply":"2023-10-01T13:56:43.842620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Import Required Libraries","metadata":{"_uuid":"c069ac38-8b2e-41b5-9709-bafc79c7c241","_cell_guid":"f7627f69-1840-4256-a6bd-d5305c08bb82","trusted":true}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n\nplt.rcParams['font.size'] = 14","metadata":{"_uuid":"dbde5eaf-ed31-4ca2-b8bf-c0c8e985ef4a","_cell_guid":"a8d9475a-c7ea-41cd-a678-a2c42249b16d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:56:43.845295Z","iopub.execute_input":"2023-10-01T13:56:43.846166Z","iopub.status.idle":"2023-10-01T13:56:58.964603Z","shell.execute_reply.started":"2023-10-01T13:56:43.846134Z","shell.execute_reply":"2023-10-01T13:56:58.963508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the translation dictionary\ntranslate = {\n    \"cane\": \"dog\",\n    \"cavallo\": \"horse\",\n    \"elefante\": \"elephant\",\n    \"farfalla\": \"butterfly\",\n    \"gallina\": \"chicken\",\n    \"gatto\": \"cat\",\n    \"mucca\": \"cow\",\n    \"pecora\": \"sheep\",\n    \"ragno\": \"spider\",\n    \"scoiattolo\": \"squirrel\",\n}","metadata":{"_uuid":"1089f062-8b72-4a58-a8de-0a552e467d62","_cell_guid":"0173b0b8-6a15-47d6-a1e8-ee95f729ece6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:56:58.965830Z","iopub.execute_input":"2023-10-01T13:56:58.966435Z","iopub.status.idle":"2023-10-01T13:56:58.971980Z","shell.execute_reply.started":"2023-10-01T13:56:58.966398Z","shell.execute_reply":"2023-10-01T13:56:58.970681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Set Parameters","metadata":{"_uuid":"1faa2608-a6d3-43ac-b502-d8d86959dbba","_cell_guid":"a132f19b-c97e-48dc-97ad-fb3e9368519a","trusted":true}},{"cell_type":"code","source":"# Define the batch size for training. It specifies the number of images to process in each training batch.\nbatch_size = 32\n\n# Define the image size. This is the size to which all input images will be resized.\nimg_size = 224\n\n# Define the directory where your image dataset is located. \n# Change this path to the directory containing your dataset.\ndirectory = '/kaggle/input/animals10/raw-img'","metadata":{"_uuid":"6366318c-7180-441f-b143-3fe13770f7dc","_cell_guid":"c75d0d06-5067-4e2c-bacd-bf3b05b32d3c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:56:58.975160Z","iopub.execute_input":"2023-10-01T13:56:58.975810Z","iopub.status.idle":"2023-10-01T13:56:58.985871Z","shell.execute_reply.started":"2023-10-01T13:56:58.975787Z","shell.execute_reply":"2023-10-01T13:56:58.985012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: Create Image Data Generators","metadata":{"_uuid":"aacc1dff-47b3-4b09-84fc-e25b4e298a88","_cell_guid":"76c4b649-4280-453c-9d42-33f8eb238945","trusted":true}},{"cell_type":"code","source":"# Create an ImageDataGenerator object to preprocess and augment the image data.\ndatagen = ImageDataGenerator(\n    rescale=1/255.,             # Rescale pixel values to a range of [0, 1]\n    zoom_range=0.2,             # Randomly zooming images by up to 20%\n    horizontal_flip=True,       # Randomly flip images horizontally\n    validation_split=0.15       # Split the data into training and validation sets (85% for training)\n)","metadata":{"_uuid":"506712fd-4ab1-40bf-96b9-2ab53f651359","_cell_guid":"1625d4b0-1cdd-4392-939b-52c5d0c0ff0c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:56:58.987285Z","iopub.execute_input":"2023-10-01T13:56:58.987843Z","iopub.status.idle":"2023-10-01T13:56:59.003050Z","shell.execute_reply.started":"2023-10-01T13:56:58.987813Z","shell.execute_reply":"2023-10-01T13:56:59.002230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Create Data Generators for Training and Validation","metadata":{"_uuid":"f05f5522-68aa-482b-a60e-9cf3e5abf30a","_cell_guid":"8244a8d0-73bd-4553-acd9-b4086c1e93de","trusted":true}},{"cell_type":"code","source":"# Create a data generator for the training set\ntrain_generator = datagen.flow_from_directory(\n    directory,                             # The directory where the image data is located\n    target_size=(img_size, img_size),      # The target size to which all images will be resized\n    batch_size=batch_size,                 # The batch size for training data\n    shuffle=True,                          # Shuffle the training data for randomness\n    subset='training',                     # Specify that this is the training subset\n    class_mode='categorical'               # The class mode for categorical classification\n)\n\n# Create a data generator for the validation set\nvalidation_generator = datagen.flow_from_directory(\n    directory,                             # The same directory as the training data\n    target_size=(img_size, img_size),      # The same target size as for training\n    batch_size=batch_size,                 # The same batch size as for training\n    shuffle=False,                         # Do not shuffle the validation data\n    subset='validation',                   # Specify that this is the validation subset\n    class_mode='categorical'               # The same class mode as for training\n)","metadata":{"_uuid":"214bd1c6-4f39-4808-a1b8-8c60d5d8ea22","_cell_guid":"b569234b-ada3-4b88-83a2-0aaea522905d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:56:59.004317Z","iopub.execute_input":"2023-10-01T13:56:59.004725Z","iopub.status.idle":"2023-10-01T13:57:23.054465Z","shell.execute_reply.started":"2023-10-01T13:56:59.004695Z","shell.execute_reply":"2023-10-01T13:57:23.053571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5: Prepare Labels and Display Sample Images","metadata":{"_uuid":"53ef189f-93e2-47ea-aa5e-bacac9e0a7ee","_cell_guid":"429fea71-97d9-4aa9-88e4-355b948e22bb","trusted":true}},{"cell_type":"code","source":"# Load the translated class names for printing\nlabels = [k for k in train_generator.class_indices]\ntranslated_labels = [translate[label] for label in labels]\n\n# Get the class labels from the data generator\nlabels = [k for k in train_generator.class_indices]\n\n# Generate a batch of data for display\nsample_generate = train_generator.__next__()\n\n# Extract the images and their corresponding titles (class labels)\nimages = sample_generate[0]\ntitles = sample_generate[1]\n\n# Create a figure to display the sample images\nplt.figure(figsize=(20, 20))\n\n# Loop through and display 15 sample images\nfor i in range(15):\n    # Create subplots in a grid of 5x5\n    plt.subplot(5, 5, i+1)\n    \n    # Adjust spacing between subplots\n    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n    \n    # Display the image\n    plt.imshow(images[i])\n    \n    # Set the title of the subplot to the corresponding class label\n    # Use np.argmax to find the index of the class with the highest probability\n    plt.title(f'Class: {translated_labels[np.argmax(titles[i], axis=0)]}')\n    \n    # Turn off axis labels for cleaner visualization\n    plt.axis(\"off\")\n\n# Show the figure with the sample images and their labels\nplt.show()","metadata":{"_uuid":"6423ef65-958c-46fa-a06b-1b7a8f1e7df3","_cell_guid":"427a0f55-4132-4955-8182-ba1b9c2bd151","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:57:23.055673Z","iopub.execute_input":"2023-10-01T13:57:23.055999Z","iopub.status.idle":"2023-10-01T13:57:25.294805Z","shell.execute_reply.started":"2023-10-01T13:57:23.055968Z","shell.execute_reply":"2023-10-01T13:57:25.293946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6: Load the Pretrained VGG16 Model","metadata":{"_uuid":"98b9ac4c-b48f-4d95-a392-831d0daa1b01","_cell_guid":"0a71ff54-17fe-47d2-b08f-20344ae2654c","trusted":true}},{"cell_type":"code","source":"# Define the input image size (224x224 pixels)\nimg_size = 224\n\n# Load the VGG16 model with specific configurations\nbase_model = VGG16(include_top=False,  # Exclude the fully connected layers at the top\n                  weights='imagenet',  # Initialize the model with pretrained ImageNet weights\n                  input_shape=(img_size, img_size, 3))  # Input shape: 224x224 pixels with 3 color channels (RGB)\n\n# Display a summary of the base model architecture\nbase_model.summary()","metadata":{"_uuid":"3e017703-7e16-49de-b927-89f0a562d868","_cell_guid":"824c13db-5dcd-4428-8b3d-8ed9baf5bcc6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:57:25.296109Z","iopub.execute_input":"2023-10-01T13:57:25.296887Z","iopub.status.idle":"2023-10-01T13:57:33.068424Z","shell.execute_reply.started":"2023-10-01T13:57:25.296854Z","shell.execute_reply":"2023-10-01T13:57:33.067698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7: Freeze the Bottom Layers of the Model","metadata":{"_uuid":"039a434a-1083-4f2d-99c1-c4395d3f2c8e","_cell_guid":"47053c8c-b788-434d-a853-c0993a8deb5b","trusted":true}},{"cell_type":"code","source":"# Freezing layers means making them non-trainable, so their weights won't be updated during training.\n\n# Loop through all layers in the base_model except the last 4 layers and set them as non-trainable.\n# This allows us to retain the feature extraction capabilities of the pretrained model while customizing the top layers.\nfor layer in base_model.layers[:-4]:\n    layer.trainable = False\n\n# After this loop, the layers in the base_model from the input up to the fourth-to-last layer will remain non-trainable.\n# Only the last 4 layers (typically fully connected layers) will be trainable for fine-tuning.\n# This is a common strategy in transfer learning to adapt a pretrained model to a specific task while preserving its learned features.\n# It helps prevent overfitting when you have limited data for your specific task.","metadata":{"_uuid":"1f32fe86-bf98-49af-b361-bcbe5d41b2dc","_cell_guid":"f227a036-8f17-498f-a4b9-4de8e11200b3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:57:33.069442Z","iopub.execute_input":"2023-10-01T13:57:33.069777Z","iopub.status.idle":"2023-10-01T13:57:33.086036Z","shell.execute_reply.started":"2023-10-01T13:57:33.069745Z","shell.execute_reply":"2023-10-01T13:57:33.085236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8: Define Model Callbacks","metadata":{"_uuid":"216c5022-ef14-46e2-a44f-efd5cd85ef32","_cell_guid":"3d3a46e8-0c2d-4ce2-a9d9-6e78b58413f1","trusted":true}},{"cell_type":"code","source":"# Define a name for the model checkpoint file\nmodel_name = 'model.h5'\n\n# Create a ModelCheckpoint callback\n# - `monitor='val_loss'`: Monitor the validation loss during training.\n# - `mode='min'`: Save the model when the monitored quantity (validation loss) is minimized.\n# - `save_best_only=True`: Only save the model when the validation loss improves.\n# - `verbose=1`: Display progress information.\ncheckpoint = ModelCheckpoint(model_name,\n                            monitor='val_loss',  # Monitor validation loss\n                            mode='min',          # Save when validation loss is minimized\n                            save_best_only=True, # Save only the best model\n                            verbose=1)           # Display progress\n\n# Create an EarlyStopping callback\n# - `monitor='val_loss'`: Monitor the validation loss during training.\n# - `min_delta=0`: Minimum change in validation loss to be considered an improvement.\n# - `patience=5`: Number of epochs with no improvement after which training will stop.\n# - `verbose=1`: Display progress information.\n# - `restore_best_weights=True`: Restore model weights to the best recorded epoch when training stops.\nearlystopping = EarlyStopping(monitor='val_loss',      # Monitor validation loss\n                             min_delta=0,            # Minimum improvement in loss\n                             patience=5,             # Number of epochs with no improvement\n                             verbose=1,              # Display progress\n                             restore_best_weights=True) # Restore best weights\n\n# These callbacks are used during model training to save the best model and stop early if no improvement is observed.","metadata":{"_uuid":"7141b54a-dfc3-427c-97da-ea5cb35cefee","_cell_guid":"1cdf26eb-d8fc-4e33-aa62-8045e3e6cf16","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:57:33.088736Z","iopub.execute_input":"2023-10-01T13:57:33.089081Z","iopub.status.idle":"2023-10-01T13:57:33.100985Z","shell.execute_reply.started":"2023-10-01T13:57:33.089050Z","shell.execute_reply":"2023-10-01T13:57:33.099773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9: Build and Compile the Custom Model","metadata":{"_uuid":"3c8d17b2-126c-4442-b277-11acc04b6b7b","_cell_guid":"0d7b51ee-b1cf-4ff7-97ee-608b96bccd9a","trusted":true}},{"cell_type":"code","source":"# Get the output from the pretrained VGG16 base model\nlast_output = base_model.output\n\n# Add a Global Average Pooling 2D layer to reduce the spatial dimensions of the feature maps\nx = GlobalAveragePooling2D()(last_output)\n\n# Add a Dense layer with 512 units and ReLU activation function\nx = Dense(512, activation='relu')(x)\n\n# Add the final Dense layer with 10 units (assuming it's a 10-class classification task) and softmax activation function\noutputs = Dense(10, activation='softmax')(x)\n\n# Create the custom model by specifying the input (base_model.inputs) and output (outputs)\nmodel = Model(inputs=base_model.inputs, outputs=outputs)\n\n# Compile the model with the Adam optimizer and categorical cross-entropy loss function\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# The custom model is now built and compiled, ready for training.","metadata":{"_uuid":"588d4b38-844a-4b3b-94bf-35c7aa83f26b","_cell_guid":"dc488f7e-5c0e-475d-aaf2-518367477c29","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T13:57:33.102294Z","iopub.execute_input":"2023-10-01T13:57:33.102902Z","iopub.status.idle":"2023-10-01T13:57:33.168776Z","shell.execute_reply.started":"2023-10-01T13:57:33.102869Z","shell.execute_reply":"2023-10-01T13:57:33.167887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 10: Train the Model","metadata":{"_uuid":"5782b0f5-26c7-4889-a38c-1f4071f09920","_cell_guid":"c2830bed-3a98-4142-a2ce-40c2e342f438","trusted":true}},{"cell_type":"code","source":"# Fit the custom model to the training data using the data generator.\n# The training runs for a specified number of epochs (in this case, 3).\n# The validation data is used to monitor the model's performance during training.\n# Callbacks are used to save the best model checkpoint and implement early stopping.\n\nhistory = model.fit(\n    train_generator,                      # Training data generator\n    epochs=3,                             # Number of training epochs\n    validation_data=validation_generator,  # Validation data generator\n    callbacks=[checkpoint, earlystopping]  # List of callbacks for monitoring and saving\n)\n\n# After training is complete, you can analyze the training history to understand\n# how the model's performance evolved during training.","metadata":{"_uuid":"219a5d34-f12c-4393-a90a-46e541aa6abd","_cell_guid":"b241938e-a129-476d-a130-f1a9fba7612e","collapsed":false,"execution":{"iopub.status.busy":"2023-10-01T12:21:41.062569Z","iopub.execute_input":"2023-10-01T12:21:41.062853Z","iopub.status.idle":"2023-10-01T12:43:36.163781Z","shell.execute_reply.started":"2023-10-01T12:21:41.062826Z","shell.execute_reply":"2023-10-01T12:43:36.162829Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 10.1 Visualize model loss and accuracy","metadata":{"_uuid":"88710312-0acf-40d0-a4e0-5f9b62a27411","_cell_guid":"d1204105-edc5-4308-8133-86d865f8833f","trusted":true}},{"cell_type":"code","source":"# Plot the training and validation loss over epochs.\nplt.figure(figsize=(20, 8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(20, 8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()\n\n# These plots provide insights into the model's convergence and performance on\n# both the training and validation datasets.","metadata":{"_uuid":"cb8c1e24-c3f1-4426-8fe2-69d0fa399c46","_cell_guid":"dfb9f20f-3e5f-4549-8f9e-97e5a9a7d9d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T14:02:31.047462Z","iopub.execute_input":"2023-10-01T14:02:31.047830Z","iopub.status.idle":"2023-10-01T14:02:31.087793Z","shell.execute_reply.started":"2023-10-01T14:02:31.047796Z","shell.execute_reply":"2023-10-01T14:02:31.086083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 11: Visualize Model Loss and Accuracy","metadata":{"_uuid":"cc6e30cd-12a6-41a2-b5b1-ba578048aa17","_cell_guid":"c3a43513-24cf-48e7-b72f-150657c37d24","trusted":true}},{"cell_type":"code","source":"# Import necessary libraries\nimport matplotlib.pyplot as plt\n\n# Create a figure with a specified size for loss visualization\nplt.figure(figsize=(20, 8))\n\n# Plot the training loss curve\nplt.plot(history.history['loss'], label='Training Loss')\n\n# Plot the validation loss curve\nplt.plot(history.history['val_loss'], label='Validation Loss')\n\n# Set the title of the plot\nplt.title('Model Loss')\n\n# Label the y-axis\nplt.ylabel('Loss')\n\n# Label the x-axis\nplt.xlabel('Epoch')\n\n# Add a legend to the plot to distinguish training and validation curves\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Save the loss curve plot as an image\nplt.savefig('loss_curve.png')\n\n# Display the loss curve plot\nplt.show()\n\n# Create another figure with a specified size for accuracy visualization\nplt.figure(figsize=(20, 8))\n\n# Plot the training accuracy curve\nplt.plot(history.history['accuracy'], label='Training Accuracy')\n\n# Plot the validation accuracy curve\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n\n# Set the title of the plot\nplt.title('Model Accuracy')\n\n# Label the y-axis\nplt.ylabel('Accuracy')\n\n# Label the x-axis\nplt.xlabel('Epoch')\n\n# Add a legend to the plot to distinguish training and validation curves\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Save the accuracy curve plot as an image\nplt.savefig('accuracy_curve.png')\n\n# Display the accuracy curve plot\nplt.show()","metadata":{"_uuid":"34c165c9-a5ab-4d28-9eca-b72a19757bd4","_cell_guid":"350b78ae-4b35-4de8-8d7d-1de8cc4993d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T14:03:02.434738Z","iopub.execute_input":"2023-10-01T14:03:02.435076Z","iopub.status.idle":"2023-10-01T14:03:02.478802Z","shell.execute_reply.started":"2023-10-01T14:03:02.435039Z","shell.execute_reply":"2023-10-01T14:03:02.477657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 12: Evaluate the Model","metadata":{"_uuid":"8daec9d2-95ae-412c-8569-c7c9c2d5b1f8","_cell_guid":"88663e9c-f50a-4c95-93e6-5fc1fedc2bec","trusted":true}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report\n\n# Load the best saved model\nmodel = tf.keras.models.load_model('/kaggle/input/my-model/my_model.h5')\n\n# Get the true labels for the validation data\ny_test = validation_generator.classes\n\n# Make predictions on the validation data\ny_pred = model.predict(validation_generator)\n\n# Make a copy of prediction probabilities for later use\ny_pred_probs = y_pred.copy()\n\n# Convert predicted probabilities to integer class labels\ny_pred_int = np.argmax(y_pred_probs, axis=1)\n\n# Define the translation dictionary\ntranslate = {\n    0: \"dog\",\n    1: \"horse\",\n    2: \"elephant\",\n    3: \"butterfly\",\n    4: \"chicken\",\n    5: \"cat\",\n    6: \"cow\",\n    7: \"sheep\",\n    8: \"spider\",\n    9: \"squirrel\",\n}\n\n# Translate class labels using the dictionary\ny_test_translated = [translate[label] for label in y_test]\ny_pred_translated = [translate[label] for label in y_pred_int]\n\n# Print a classification report with translated class names\n# The classification report provides precision, recall, F1-score, and support for each class.\n# It helps evaluate the model's performance on each class.\nprint(classification_report(y_test_translated, y_pred_translated, target_names=translate.values()))","metadata":{"_uuid":"ef3ffee4-8eed-416a-8282-6e924c1e2805","_cell_guid":"af757293-b741-45be-a437-8bd7f1899d34","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T14:00:59.412921Z","iopub.execute_input":"2023-10-01T14:00:59.413300Z","iopub.status.idle":"2023-10-01T14:02:31.045274Z","shell.execute_reply.started":"2023-10-01T14:00:59.413269Z","shell.execute_reply":"2023-10-01T14:02:31.044137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 13: Visualize Confusion Matrix","metadata":{"_uuid":"5864b4fb-6fc0-43f6-b1fd-3ee8af93be41","_cell_guid":"1ce2a369-ed9a-47ce-bf26-8601b947053e","trusted":true}},{"cell_type":"code","source":"# Calculate the confusion matrix using the true labels (y_test_translated) and predicted labels (y_pred_translated)\nconfusion_mat = confusion_matrix(y_test_translated, y_pred_translated, labels=list(translate.values()))\n\n# Create a figure for the heatmap with a specified size\nplt.figure(figsize=(10, 8))\n\n# Create a heatmap to visualize the confusion matrix\nsns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=list(translate.values()), yticklabels=list(translate.values()))\n\n# Add labels to the x and y axes of the heatmap\nplt.xlabel('Predicted')  # Label for the x-axis\nplt.ylabel('True')       # Label for the y-axis\n\n# Set the title for the heatmap\nplt.title('Confusion Matrix')\n\n# Display the confusion matrix heatmap\nplt.savefig('confusion_matrix.png')\n\n# Display the confusion matrix heatmap\nplt.show()","metadata":{"_uuid":"db4434f6-b029-4fab-b0b4-4f508b6d7f78","_cell_guid":"3dcc330e-e022-4db6-96db-fd4b004ae03d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T14:03:11.092994Z","iopub.execute_input":"2023-10-01T14:03:11.093360Z","iopub.status.idle":"2023-10-01T14:03:11.809239Z","shell.execute_reply.started":"2023-10-01T14:03:11.093313Z","shell.execute_reply":"2023-10-01T14:03:11.808387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 14: Print Accuracy, Precision, and Recall","metadata":{"_uuid":"236d7fc5-50a5-4aee-b42e-527e73e81897","_cell_guid":"f1b8520b-d7d4-4195-a608-7e4ec751ebc1","trusted":true}},{"cell_type":"code","source":"# Import necessary metrics functions from scikit-learn\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Calculate the accuracy score\naccuracy = accuracy_score(y_test, y_pred_int)\n\n# Calculate the weighted precision score (averaging precision for all classes with weight)\nprecision = precision_score(y_test, y_pred_int, average='weighted')\n\n# Calculate the weighted recall score (averaging recall for all classes with weight)\nrecall = recall_score(y_test, y_pred_int, average='weighted')\n\n# Print the calculated metrics\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precision: {precision}\")\nprint(f\"Recall: {recall}\")\n\n# Create a figure and axis for the plot\nfig, ax = plt.subplots(figsize=(8, 4))\n\n# Add the text with metrics to the plot\ntext = f\"Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\"\nax.text(0.5, 0.5, text, ha='center', va='center', fontsize=12, color='black')\n\n# Remove axis labels and ticks\nax.axis('off')\n\n# Save the figure as an image\nplt.savefig('Accuracy, Precision, and Recall.png', bbox_inches='tight', dpi=300)","metadata":{"_uuid":"0616a8e6-1b81-427e-8cfc-30f7c18219d6","_cell_guid":"5fcde28f-838d-41fc-b492-5935c5dc91d9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-10-01T14:03:19.224400Z","iopub.execute_input":"2023-10-01T14:03:19.225235Z","iopub.status.idle":"2023-10-01T14:03:19.461606Z","shell.execute_reply.started":"2023-10-01T14:03:19.225168Z","shell.execute_reply":"2023-10-01T14:03:19.460263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 15: Save the Trained Model","metadata":{"_uuid":"1dedd532-fe08-4e78-96a3-cfa31e09f8ae","_cell_guid":"ca9d1714-7fed-4c70-9c0e-913c5929f6a7","trusted":true}},{"cell_type":"code","source":"# After training your model, it's a good practice to save it so you can use it later for inference or further training.\n# We save the model with the name 'my_model.h5', but you can choose a different name if desired.\nmodel.save('my_model.h5')","metadata":{"_uuid":"b383916c-0738-4c5a-bc1d-ef88ce599467","_cell_guid":"3d58ace7-578a-48ef-bf4d-d8ba271bb7b3","collapsed":false,"execution":{"iopub.status.busy":"2023-10-01T13:03:43.201681Z","iopub.execute_input":"2023-10-01T13:03:43.202022Z","iopub.status.idle":"2023-10-01T13:03:43.571987Z","shell.execute_reply.started":"2023-10-01T13:03:43.201994Z","shell.execute_reply":"2023-10-01T13:03:43.570641Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}